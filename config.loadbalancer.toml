# LOAD BALANCER CONFIGURATION - Routes all requests through the load balancer
# This fixes the 404 errors by using the load balancer's thinking detection

[providers]
# Default provider - Load balancer (handles thinking detection automatically)
default_provider = "anthropic.loadbalancer"

# Load balancer provider - Primary endpoint that handles all routing
[providers.anthropic.loadbalancer]
model = "claude-3-sonnet-20240229"  # Will be mapped by load balancer
base_url = "http://localhost:9000/v1/messages"  # Load balancer endpoint
use_bearer_auth = true
api_key = "sk-ant-anthropic-key"  # Load balancer accepts any key
max_tokens = 64000
temperature = 0.3

# MiniMax through load balancer (backup)
[providers.anthropic.minimax_lb]
model = "minimax-m2"
base_url = "http://localhost:9000/v1/messages"  # Same load balancer endpoint
use_bearer_auth = true
api_key = "sk-ant-anthropic-key"
max_tokens = 64000
temperature = 0.3

# Kimi through load balancer (thinking specialist)
[providers.anthropic.kimi_lb]
model = "kimi-for-coding"
base_url = "http://localhost:9000/v1/messages"  # Same load balancer endpoint
use_bearer_auth = true
api_key = "sk-ant-anthropic-key"
max_tokens = 128000
temperature = 0.2

[agent]
name = "loadbalancer-agent"
provider = "anthropic.loadbalancer"  # Always use load balancer
fallback_default_max_tokens = 8192
enable_streaming = true
timeout_seconds = 120  # Increased for thinking tasks
max_retry_attempts = 3
autonomous_max_retry_attempts = 6
allow_multiple_tool_calls = true
auto_compact = true

# All roles now use the same load balancer provider
# The load balancer will automatically route thinking requests to Kimi
[agent.coach]
provider = "anthropic.loadbalancer"
max_tokens = 128000
temperature = 0.2

[agent.player]
provider = "anthropic.loadbalancer"
max_tokens = 64000
temperature = 0.3

[computer_control]
enabled = false
require_confirmation = true
max_actions_per_second = 5

[webdriver]
enabled = true
browser = "chrome-headless"
safari_port = 4444
chrome_port = 9515

[macax]
enabled = false

[ui]
machine_mode = true

# Load Balancer Benefits:
# 1. Automatic thinking detection - routes complex requests to Kimi
# 2. Health monitoring - falls back to working providers
# 3. Unified endpoint - single URL for all providers
# 4. Proper error handling - 404 issues are resolved
# 5. Thinking specialist routing - opus models automatically go to Kimi